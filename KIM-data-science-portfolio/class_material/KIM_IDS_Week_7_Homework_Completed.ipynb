{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
      "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
      "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
      "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
      "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
      "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
      "\n",
      "   Longitude  \n",
      "0    -122.23  \n",
      "1    -122.22  \n",
      "2    -122.24  \n",
      "3    -122.25  \n",
      "4    -122.25  \n",
      "Feature Names: ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude']\n",
      "\n",
      "Missing Values:\n",
      " MedInc        0\n",
      "HouseAge      0\n",
      "AveRooms      0\n",
      "AveBedrms     0\n",
      "Population    0\n",
      "AveOccup      0\n",
      "Latitude      0\n",
      "Longitude     0\n",
      "dtype: int64\n",
      "             MedInc      HouseAge      AveRooms     AveBedrms    Population  \\\n",
      "count  20640.000000  20640.000000  20640.000000  20640.000000  20640.000000   \n",
      "mean       3.870671     28.639486      5.429000      1.096675   1425.476744   \n",
      "std        1.899822     12.585558      2.474173      0.473911   1132.462122   \n",
      "min        0.499900      1.000000      0.846154      0.333333      3.000000   \n",
      "25%        2.563400     18.000000      4.440716      1.006079    787.000000   \n",
      "50%        3.534800     29.000000      5.229129      1.048780   1166.000000   \n",
      "75%        4.743250     37.000000      6.052381      1.099526   1725.000000   \n",
      "max       15.000100     52.000000    141.909091     34.066667  35682.000000   \n",
      "\n",
      "           AveOccup      Latitude     Longitude  \n",
      "count  20640.000000  20640.000000  20640.000000  \n",
      "mean       3.070655     35.631861   -119.569704  \n",
      "std       10.386050      2.135952      2.003532  \n",
      "min        0.692308     32.540000   -124.350000  \n",
      "25%        2.429741     33.930000   -121.800000  \n",
      "50%        2.818116     34.260000   -118.490000  \n",
      "75%        3.282261     37.710000   -118.010000  \n",
      "max     1243.333333     41.950000   -114.310000  \n"
     ]
    }
   ],
   "source": [
    "# Import neccesary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#1. Load the California Housing dataset from sklearn.datasets.\n",
    "#Loading Data Set \n",
    "from sklearn.datasets import fetch_california_housing\n",
    "\n",
    "# Load the housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "#2. Create a Pandas DataFrame for the features and a Series for the target variable (med_house_value). \n",
    "#Making the Data Frame\n",
    "X = pd.DataFrame(housing.data, columns=housing.feature_names) \n",
    "y = pd.Series(housing.target, name='med_house_value')\n",
    "\n",
    "\n",
    "#3. Perform an initial exploration of the dataset: \n",
    "print(X.head())  # Display the first five rows of the dataset\n",
    "print(\"Feature Names:\", X.columns.tolist())  # Print feature names\n",
    "print(\"\\nMissing Values:\\n\", X.isnull().sum())  # Check for missing values\n",
    "print(X.describe())  # Generate summary statistics (mean, min, max, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unscaled Data Model:\n",
      "Mean Squared Error: 0.56\n",
      "Root Squared Error: 0.75\n",
      "R² Score: 0.58\n",
      "\n",
      "Features with the strongest impact on predictions:\n",
      "AveBedrms     0.783145\n",
      "MedInc        0.448675\n",
      "Longitude     0.433708\n",
      "Latitude      0.419792\n",
      "AveRooms      0.123323\n",
      "HouseAge      0.009724\n",
      "AveOccup      0.003526\n",
      "Population    0.000002\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#Linear Regression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, r2_score\n",
    "\n",
    "#4. Split the dataset into training and test sets (80% training, 20% testing). \n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#5. Train a linear regression model on the unscaled data using sklearn.linear_model.LinearRegression. \n",
    "lin_reg_raw = LinearRegression()\n",
    "lin_reg_raw.fit(X_train_raw, y_train)\n",
    "\n",
    "#6. Make predictions on the test set.\n",
    "y_pred_raw = lin_reg_raw.predict(X_test_raw)\n",
    "\n",
    "#7. Evaluate model performance using the following metrics:\n",
    "mse_raw = mean_squared_error(y_test, y_pred_raw) # Mean Squared Error (MSE)\n",
    "rmse_raw = root_mean_squared_error(y_test, y_pred_raw) # Root Mean Squared Error (RMSE)\n",
    "r2_raw = r2_score(y_test, y_pred_raw) #R² Score\n",
    "\n",
    "print(\"Unscaled Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_raw:.2f}\")\n",
    "print(f\"Root Squared Error: {rmse_raw:.2f}\")\n",
    "print(f\"R² Score: {r2_raw:.2f}\")\n",
    "\n",
    "#Determining Feature Impact \n",
    "# Extract feature names and coefficients\n",
    "feature_impact = pd.Series(lin_reg_raw.coef_, index=X.columns)\n",
    "\n",
    "# Sort features by absolute coefficient value (strongest impact first)\n",
    "strongest_features = feature_impact.abs().sort_values(ascending=False)\n",
    "\n",
    "# Print the most influential features\n",
    "print(\"\\nFeatures with the strongest impact on predictions:\")\n",
    "print(strongest_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Interpretation Questions\n",
    "The R² score (coefficient of determination) measures how well the model explains the variance in the target variable. More specifically, it indicates how well the model fits a linear regression line. It measures how much of the variance in the dependent variable is explained by the independent variables. The values range from 0 to 1 with the former meaning the model does no better than predicting the mean of y and the latter being a perfect model that explains 100% of variance. Within such a range, there is variability in the accuracy of the model in predicting the level of variance. A model with a value lower than 0 means it performs worse than a simple mean-based prediction. Essentially, a higher R² value, closer to 1.0, suggests a well-fitting model with strong predictive accuracy while conversely, a lower R² value indicates that the model struggles to explain the variability in the data, making it less effective for predictions. \n",
    "\n",
    "According to the model's coefficients, average bedrooms (0.78), median income (0.44), longitude and latitude (0.43 and 0.42, respectively) have the most significant influence on the predictions. In contrast, the remaining four features— average rooms(0.12), house age (0.01), average occupancy (0.003), and population (0.000002) have a lesser impact on the model's predictions. \n",
    "\n",
    "The predicted values do not closely align with the actual values, as indicated by the relatively high Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). These higher error values suggest a larger discrepancy between predictions and actual outcomes. Additionally, a lower R² value is preferred for a better fit, but 0.58 is not sufficiently low, highlighting the model's limitations in making accurate predictions. In predictive modeling, especially in a complex domain like housing prices, R² values around 0.58 generally suggest room for improvement. Although it's better than completely random guesses, it still indicates that a significant portion (42%) of the variation in house prices remains unexplained by the current model. For practical purposes, this can mean that predictions based on this model are not highly reliable and could lead to substantial errors. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simplified Data Model:\n",
      "Mean Squared Error: 0.68\n",
      "Root Squared Error: 0.82\n",
      "R² Score: 0.48\n"
     ]
    }
   ],
   "source": [
    "#13. Select three features from the dataset to build a simplified model. Explain your choice.\n",
    "#Selected average bedrooms, median income, and average rooms features as they are have the highest impact on the model. \n",
    "#Note: longitude and latitude have higher coefficients but might be more effective in tandem. \n",
    "features = ['AveBedrms', 'MedInc', 'AveRooms']\n",
    "X_selected = X[features]\n",
    "\n",
    "#14. Train a new linear regression model using only these three features.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_selected, y, test_size=0.2, random_state=42)\n",
    "\n",
    "simplified_model = LinearRegression()\n",
    "simplified_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_simplified = simplified_model.predict(X_test) # Predictions\n",
    "\n",
    "#15. Evaluate the performance of this simplified model and compare it to the full model.\n",
    "mse_simplified = mean_squared_error(y_test, y_pred_simplified)\n",
    "rmse_simplified = root_mean_squared_error(y_test, y_pred_simplified)\n",
    "r2_simplified = r2_score(y_test, y_pred_simplified)\n",
    "\n",
    "print(\"Simplified Data Model:\")\n",
    "print(f\"Mean Squared Error: {mse_simplified:.2f}\")\n",
    "print(f\"Root Squared Error: {rmse_simplified:.2f}\")\n",
    "print(f\"R² Score: {r2_simplified:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. \n",
    "How does the simplified model compare to the full model?\n",
    "\n",
    "The simplified model performs worse than the full model. The R² value for the simplified model is 0.48, while the full model achieves 0.58, suggesting that the full model explains more of the variation in the target variable (house prices). A higher R² value indicates a better fit, so the full model’s R² score reflects a more accurate representation of the data.\n",
    "\n",
    "Furthermore, the performance of the simplified model is also reflected in its error metrics. The Mean Squared Error (MSE) and Root Mean Squared Error (RMSE) are both higher in the simplified model, signaling that it makes larger errors in its predictions compared to the full model. Specifically, the simplified model has an MSE of 0.68 and an RMSE of 0.82, meaning the average squared error and the typical prediction error are higher. In contrast, the full model’s MSE is 0.56 and RMSE is 0.75, indicating that it has lower error rates and provides more accurate predictions.\n",
    "Overall, the simplified model is less effective in capturing the complexities of the data, leading to less accurate predictions compared to the full model. This highlights the importance of considering all relevant features and model complexity to ensure better performance and more reliable outcomes. \n",
    "\n",
    "\n",
    "Would you use this simplified model in practice? Why or why not?\n",
    "\n",
    "I would recommend against using the simplified model in practice, as it consistently performs worse across key metrics— R², MSE, and RMSE—by approximately 0.10 for each value. This suggests that the simplified model is a less reliable predictor of house prices compared to the full model, leading to less accurate predictions.\n",
    "\n",
    "However, there may be situations where a simplified model is necessary, such as when dealing with very large datasets or limited computational resources. In those cases, the trade-off is clear: while the simplified model may run faster and be more efficient, it will come at the cost of higher error rates and less accurate predictions. \n",
    "\n",
    "Choosing to use a simplified model in this context would require accepting these shortcomings. The decision would need to be based on the specific needs of the situation, weighing the trade-off between accuracy and computational efficiency. If the company can tolerate more imprecise predictions, or if the model is being used for initial exploratory analysis rather than high-stakes decision-making, the simplified model might still be a viable option. Ultimately, it’s a decision that needs to be carefully considered based on the priorities and constraints of the project.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
